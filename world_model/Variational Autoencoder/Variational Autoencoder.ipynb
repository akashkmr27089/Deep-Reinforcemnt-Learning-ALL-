{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torchsummary import summary   #used for finding summary\n",
    "from torch.utils.data import DataLoader  \n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import time\n",
    "from progressbar import *\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available \n"
     ]
    }
   ],
   "source": [
    "#Enable cuda if cuda is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device, \"is available \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Making "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 66, 66]             896\n",
      "              ReLU-2           [-1, 32, 66, 66]               0\n",
      "         MaxPool2d-3           [-1, 32, 33, 33]               0\n",
      "            Conv2d-4           [-1, 64, 35, 35]          18,496\n",
      "              ReLU-5           [-1, 64, 35, 35]               0\n",
      "         MaxPool2d-6           [-1, 64, 17, 17]               0\n",
      "================================================================\n",
      "Total params: 19,392\n",
      "Trainable params: 19,392\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 3.73\n",
      "Params size (MB): 0.07\n",
      "Estimated Total Size (MB): 3.85\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1          [-1, 128, 16, 16]         131,200\n",
      "              ReLU-2          [-1, 128, 16, 16]               0\n",
      "   ConvTranspose2d-3           [-1, 64, 32, 32]         131,136\n",
      "              ReLU-4           [-1, 64, 32, 32]               0\n",
      "   ConvTranspose2d-5            [-1, 3, 64, 64]           3,075\n",
      "================================================================\n",
      "Total params: 265,411\n",
      "Trainable params: 265,411\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.07\n",
      "Forward/backward pass size (MB): 1.59\n",
      "Params size (MB): 1.01\n",
      "Estimated Total Size (MB): 2.68\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(32, 64, 3, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, data):\n",
    "        return self.encoder(data)\n",
    "    \n",
    "class decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "                nn.ConvTranspose2d(64, 128, 4,stride=1, padding = 2),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(128, 64, 4, stride = 2, padding = 1),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(64,3,4, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "\n",
    "encoder_model = encoder().to(device)\n",
    "decoder_model = decoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "summary(encoder_model, (3,64,64))   #used for finding summary for encoder \n",
    "summary(decoder_model, (64,17,17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vae(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(vae, self).__init__()\n",
    "        self.encoder = encoder().to(device)\n",
    "        self.decoder = decoder().to(device)\n",
    "        self.linear_dense = nn.Linear(17,8)\n",
    "        \n",
    "    def forward(self,data):\n",
    "        print(data.shape)\n",
    "        x = self.encoder.forward(data)\n",
    "        x = self.linear_dense(x)\n",
    "        return self.decoder.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 64, 64])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 66, 66]             896\n",
      "              ReLU-2           [-1, 32, 66, 66]               0\n",
      "         MaxPool2d-3           [-1, 32, 33, 33]               0\n",
      "            Conv2d-4           [-1, 64, 35, 35]          18,496\n",
      "              ReLU-5           [-1, 64, 35, 35]               0\n",
      "         MaxPool2d-6           [-1, 64, 17, 17]               0\n",
      "            Linear-7            [-1, 64, 17, 8]             144\n",
      "   ConvTranspose2d-8           [-1, 128, 16, 7]         131,200\n",
      "              ReLU-9           [-1, 128, 16, 7]               0\n",
      "  ConvTranspose2d-10           [-1, 64, 32, 14]         131,136\n",
      "             ReLU-11           [-1, 64, 32, 14]               0\n",
      "  ConvTranspose2d-12            [-1, 3, 64, 28]           3,075\n",
      "================================================================\n",
      "Total params: 284,947\n",
      "Trainable params: 284,947\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 4.49\n",
      "Params size (MB): 1.09\n",
      "Estimated Total Size (MB): 5.63\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "vae = vae().to(device)\n",
    "summary(vae, (3,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
