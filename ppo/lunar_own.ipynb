{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import random\n",
    "from collections import namedtuple, deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "State size 8 with action size 2\n"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device =  \"cpu\"\n",
    "env = gym.make(\"LunarLanderContinuous-v2\")\n",
    "action_size = env.action_space.shape[0]\n",
    "state_size = env.observation_space.shape[0]\n",
    "\n",
    "ROLLOUT_LENGTH = 300\n",
    "DISCOUNT = 0.99\n",
    "GAE_LAMBDA = 0.95\n",
    "OPTIMIZATION_EPOCHS = 10\n",
    "MINI_BATCH_SIZE = 64\n",
    "PPO_RATIO_CLIP = 0.1\n",
    "GRADIENT_CLIP = 0.75\n",
    "HIDDEN_LAYERS = 32\n",
    "\n",
    "print(\"State size {} with action size {}\".format(state_size, action_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_init(layer, w_scale=1.0):\n",
    "    nn.init.orthogonal_(layer.weight.data)\n",
    "    layer.weight.data.mul_(w_scale)\n",
    "    nn.init.constant_(layer.bias.data, 0)\n",
    "    return layer\n",
    "\n",
    "def to_np(t):\n",
    "    return t.cpu().detach().numpy()\n",
    "\n",
    "def tensor(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x\n",
    "    x = torch.tensor(x, device=DEVICE, dtype=torch.float32)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_units, output_size, seed):\n",
    "        super(SubNetwork, self).__init__()\n",
    "        dims = (input_size,) + hidden_units        \n",
    "        self.layers = nn.ModuleList([layer_init(nn.Linear(dim_in, dim_out)) for dim_in, dim_out in zip(dims[:-1], dims[1:])])\n",
    "        self.feature_dim = dims[-1]\n",
    "        self.output_layer = layer_init(nn.Linear(self.feature_dim, output_size), 1e-3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = F.tanh(layer(x))\n",
    "        x = self.output_layer(x)    \n",
    "        return x    \n",
    "            \n",
    "class ActorAndCritic(nn.Module):\n",
    "    \n",
    "    def __init__(self, state_size, action_size, seed):\n",
    "        super(ActorAndCritic, self).__init__()\n",
    "        self.seed = random.seed(seed)\n",
    "        self.actor = SubNetwork(state_size, (HIDDEN_LAYERS, HIDDEN_LAYERS), action_size, seed)\n",
    "        self.critic = SubNetwork(state_size, (HIDDEN_LAYERS, HIDDEN_LAYERS), 1, seed)\n",
    "        self.std = nn.Parameter(torch.zeros(action_size))\n",
    "        #self.to(Config.DEVICE)\n",
    "        \n",
    "    def forward(self, obs, action=None):\n",
    "        obs = tensor(obs)\n",
    "        a = self.actor(obs)\n",
    "        v = self.critic(obs)\n",
    "        mean = F.tanh(a)\n",
    "        dist = torch.distributions.Normal(mean, F.softplus(self.std))\n",
    "        return (v, dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "ActorAndCritic(\n  (actor): SubNetwork(\n    (layers): ModuleList(\n      (0): Linear(in_features=8, out_features=32, bias=True)\n      (1): Linear(in_features=32, out_features=32, bias=True)\n    )\n    (output_layer): Linear(in_features=32, out_features=2, bias=True)\n  )\n  (critic): SubNetwork(\n    (layers): ModuleList(\n      (0): Linear(in_features=8, out_features=32, bias=True)\n      (1): Linear(in_features=32, out_features=32, bias=True)\n    )\n    (output_layer): Linear(in_features=32, out_features=1, bias=True)\n  )\n)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "network = ActorAndCritic(state_size, action_size, 0).to(device)\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actions_from_states(network, states):\n",
    "    if not isinstance(states, torch.Tensor):\n",
    "        states = torch.tensor(states, dtype=torch.float32, device=device)\n",
    "    value, distribution = network.forward(states)\n",
    "    actions = distribution.sample()\n",
    "    return to_np(actions), distribution\n",
    "\n",
    "def get_log_probability_from_actions(distribution, action):\n",
    "    if not isinstance(action, torch.Tensor):\n",
    "        action = torch.Tensor(action)\n",
    "    log_prob = distribution.log_prob(action)\n",
    "    return log_prob.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[-0.5533819 -0.6063934]\n[-1.0682343  -0.67481214]\n[-0.6873418 -1.4387639]\n[-0.93667763 -0.58069086]\n[-1.6443069 -1.1178186]\n[-0.5640476 -1.4939203]\n[-2.0048227 -0.9400481]\n[-1.1385506 -1.8745768]\n[-0.67953557 -0.9073213 ]\n[-1.6155418 -1.1281716]\n[-1.8016616 -0.96171  ]\n[-0.72881395 -0.713392  ]\n[-0.8190851 -2.767889 ]\n[-0.8583958  -0.55447936]\n[-0.8847645 -1.8550687]\n[-0.62972987 -1.7197249 ]\n[-0.9113766 -2.1528919]\n[-0.5716667  -0.73920506]\n[-1.0815481 -0.5524727]\n[-0.7813052 -0.553159 ]\n[-0.6056081 -0.6062563]\n[-4.2128825 -0.6141937]\n[-0.55996317 -0.55570626]\n[-3.6227856 -1.2892565]\n[-0.58017385 -1.1333708 ]\n[-0.59656024 -0.5636894 ]\n[-0.56163955 -1.2321153 ]\n[-0.690972  -0.8925452]\n[-0.7885031 -0.7024864]\n[-0.5536846 -0.6583319]\n[-0.727553  -0.7092635]\n[-0.5544032 -0.8956994]\n[-1.8938342 -1.0060309]\n[-0.9235957 -1.2359898]\n[-0.58892035 -1.1839755 ]\n[-0.8933141 -0.7482045]\n[-2.883668   -0.66225207]\n[-0.745499  -0.8579817]\n[-0.68677086 -0.6182796 ]\n[-0.741604   -0.60437477]\n[-0.66305447 -0.5651153 ]\n[-0.5679785 -0.8444611]\n[-1.5887463  -0.59206396]\n[-0.60327667 -1.6724906 ]\n[-1.2034824 -1.9705528]\n[-0.55259526 -0.5541626 ]\n[-0.6678979 -1.8688844]\n[-2.0354881 -0.561609 ]\n[-0.6791767  -0.60053873]\n[-0.74578184 -0.6320401 ]\n[-1.2132163 -2.5539098]\n[-2.383201  -0.5671743]\n[-0.5600568 -1.9817419]\n[-0.97551006 -0.84110487]\n[-0.55730176 -0.8583149 ]\n[-1.3287638 -1.516107 ]\n[-0.57057095 -0.55360335]\n[-1.0659543 -0.7964988]\n[-0.5708866  -0.61157143]\n[-0.6908331  -0.78339076]\n[-1.3012013 -0.6137391]\n[-0.55877995 -1.228908  ]\n[-0.56982327 -0.6870291 ]\n[-0.78927326 -2.2406168 ]\n[-0.686756  -0.5565103]\n[-0.55991423 -0.7276419 ]\n[-0.5706706 -0.8288301]\n[-0.63152397 -0.6415045 ]\n[-0.6303897 -0.56582  ]\n[-0.9729756 -2.9909072]\n[-0.64158374 -0.57341063]\n[-2.0420094 -0.6055042]\n[-1.1024463  -0.59699947]\n[-1.8350307 -0.6774933]\n[-0.5524907 -2.0874546]\n[-1.313291   -0.65378386]\n[-0.5739619 -0.5652236]\n[-0.55243385 -1.202896  ]\n[-0.8164913 -1.5286462]\n[-0.64925206 -0.6518834 ]\n[-1.5207237 -1.3887806]\n[-1.2822977 -0.6092858]\n[-0.7835467  -0.61391604]\n[-1.5613517  -0.67599726]\n[-0.9775932 -0.5686729]\n[-1.4154114 -1.4930218]\n[-0.74494004 -0.7524279 ]\n[-1.1686385  -0.97032225]\n[-0.6907363 -1.0809847]\n[-2.0156908 -0.7092839]\n[-2.1614068  -0.55526614]\n[-0.68251705 -0.5716841 ]\n[-0.88105273 -1.0658163 ]\n[-3.436986  -3.2800632]\n[-0.76336884 -1.6566838 ]\n[-0.5565241 -0.590902 ]\n[-0.77520835 -1.2999504 ]\n[-0.6995184 -0.6246348]\n[-0.560271   -0.86404043]\n[-0.99391866 -0.74286634]\n[-0.56227756 -1.1147382 ]\n[-1.0769186 -1.4656272]\n[-0.5722103  -0.55790883]\n[-0.87424517 -0.8245513 ]\n[-0.5548476 -1.1837043]\n[-1.2271092 -0.5594194]\n[-1.366543  -1.7849356]\n[-1.3258109  -0.90942144]\n[-0.55994827 -0.5524274 ]\n[-0.78675294 -0.6104877 ]\n[-0.860014 -2.79332 ]\n[-0.8173152  -0.94772434]\n[-1.3474298 -1.8534657]\n[-0.6345141 -0.6865456]\n[-3.5632076 -0.6543548]\n[-1.1873723 -2.1175067]\n[-0.7041686  -0.55815214]\n[-1.266205  -0.8858882]\n[-1.0657696  -0.78826815]\n[-0.76183504 -0.584141  ]\n[-0.648396  -2.2592776]\n[-1.2733179 -1.0918654]\n[-0.5970931 -1.1798725]\n[-1.2881256 -0.6069709]\n[-0.55242634 -0.77805376]\n[-0.55758786 -0.6309282 ]\n[-0.5531019 -0.9699023]\n[-0.56732905 -0.5904153 ]\n[-0.66978186 -0.55725145]\n[-0.9389741 -0.8243767]\n[-1.415022  -0.5524708]\n[-0.8399556  -0.56841946]\n[-0.66577274 -0.77652204]\n[-2.323831   -0.92681533]\n[-0.7036822 -1.7773565]\n[-1.2176962  -0.61234814]\n[-0.63075745 -1.8694164 ]\n[-1.3243731 -0.5729567]\n[-0.6226886 -1.4236511]\n[-0.6244765 -6.3293705]\n[-1.5870332 -0.6417912]\n"
    }
   ],
   "source": [
    "#Random walk\n",
    "state = env.reset()\n",
    "while True:\n",
    "    action, distribution = get_actions_from_states(network, state)\n",
    "    log_prob = get_log_probability_from_actions(distribution, action)\n",
    "    print(log_prob)\n",
    "    env.render()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    state = next_state\n",
    "    time.sleep(0.01)\n",
    "    if done: break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rollout:\n",
    "    def __init__(self):\n",
    "        self.actions = []\n",
    "        self.states = []\n",
    "        self.next_states = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        self.log_probs = []\n",
    "\n",
    "    def save_rollout_data(self, state, action, next_state, reward, done, log_prob):\n",
    "        self.states.append(state)\n",
    "        self.dones.append(done)\n",
    "        self.next_states.append(next_state)\n",
    "        self.actions.append(action)\n",
    "        self.log_probs.append(log_prob)\n",
    "        self.rewards.append(reward)\n",
    "\n",
    "    def stack():\n",
    "        pass\n",
    "\n",
    "    def sample(self):\n",
    "        pass\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MasterAgent():\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed):\n",
    "        self.network = ActorAndCritic(state_size, action_size, seed)\n",
    "        self.avg_score = 0\n",
    "        self.score_list = deque(maxlen=100)\n",
    "        \n",
    "    def rollout_init(self):\n",
    "        self.rollout = Rollout()\n",
    "    \n",
    "    def optimize(self):\n",
    "        pass\n",
    "\n",
    "    def step(self, state, action, next_state, reward, done, log_prob):\n",
    "        state = torch.Tensor(state, device = device).float()\n",
    "        next_state = torch.Tensor(next_state, device = device).float()\n",
    "        done = torch.Tensor(np.asarray([int(done)]), device = device)\n",
    "        log_prob = torch.Tensor(log_prob,device = device).float()\n",
    "        print(reward)\n",
    "        reward = torch.from_numpy(np.array(reward)).float().to(device)\n",
    "        self.rollout.save_rollout_data(state, action, next_state, reward, done, log_prob)\n",
    "\n",
    "    def train(self, iteration = 300):\n",
    "        self.state = env.reset()\n",
    "        for i in range(iteration):\n",
    "            score = self.run(env)\n",
    "            self.score_list.append(score)\n",
    "            self.optimize()\n",
    "            \n",
    "\n",
    "    def run(self, env):\n",
    "        self.rollout_init()\n",
    "        score = 0\n",
    "        for _ in range(ROLLOUT_LENGTH):\n",
    "            action, distribution = get_actions_from_states(network, self.state)\n",
    "            log_prob = get_log_probability_from_actions(distribution, action)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            score += reward\n",
    "            self.step(self.state, action, next_state, reward, done, log_prob)\n",
    "            self.state = next_state\n",
    "            if done:\n",
    "                print(\"done ::\")\n",
    "                state = env.reset()\n",
    "        print(\"Terminating Rollout\")\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = MasterAgent(state_size, action_size, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-1.6822729861988819\n-1.7769707745241021\n1.5995700275338731\n0.8455030373247439\n-0.21232941387847176\n-0.5229431662789977\n2.069900260704375\n0.23091047849355278\n2.7883758734073028\n-0.05187137608511649\n2.8235027222528517\n-1.1572961784098141\n1.0864126988149962\n-1.5347723274809937\n-2.3274323032559026\n-1.695044264568736\n1.210190002278441\n-1.1246487410591204\n2.9524988279789524\n-1.5124328598566978\n2.0065915482176493\n-0.13214134473037575\n0.9851526697788494\n-1.9431199683852856\n-1.2966554019340435\n-1.4433808178748109\n-1.1167082256080665\n-1.2339868258239335\n0.6700127434333286\n-1.3320208947115577\n1.1334867155859\n-1.4918790027380737\n0.9547303723916127\n2.7816275368304106\n1.0105501386580045\n1.316530174100086\n-1.4345578643577142\n-1.3886496004588764\n-0.17606720438456702\n0.5680505899652758\n-1.4245620469851588\n-1.3477102709893949\n1.3528141814781236\n-1.4388081787896272\n2.3554146139291405\n-0.15304242332038484\n2.4228806311628275\n-1.4009885041630241\n2.0283548002000544\n-1.3932165699621624\n-1.5744022745604855\n-1.6393892280492253\n-1.7311957745604605\n0.6101598845504099\n-1.6770612888029108\n1.762944754391749\n-1.7781209559445585\n-1.722149022664297\n-0.2086170993283008\n-1.9789063475735236\n-2.0054654959335165\n2.132067938062755\n-0.9450143117354491\n-2.1293623575102743\n0.35872132835944515\n-2.280537209412387\n-2.0527920082621565\n1.15649932679142\n2.027673148171914\n-2.0638250663607733\n-1.8749742669126976\n-2.1397431160134284\n1.1131897771544288\n-1.9707442483451132\n1.6302342568796517\n0.7614065544967503\n-1.2842032198213746\n-1.9314161740138867\n-2.3228028969746672\n1.2743811844687412\n-1.9152377866605832\n-1.8933501785116107\n1.3048859883025137\n0.3294642941814516\n-1.8985104057906028\n1.0010549173522156\n-0.6123926857194135\n9.178218032219327\n14.26165862911887\n0.5303140441819778\n-100\ndone ::\n0.7152892626128846\n1.6088593971497869\n1.6784479161677017\n1.1408925607952654\n2.0866363496190288\n1.3148546244199792\n-0.5777303923085754\n1.2619806644186156\n0.506477294451621\n-1.158847697245409\n1.02154989709544\n0.9380238967089838\n-0.42239347690815976\n0.5921373056862649\n0.4734401267718056\n-0.10238022785016142\n0.6778711880508547\n-1.5096087628989894\n0.206799799461038\n0.33968527889352346\n0.09671621545948028\n-1.395714955421628\n-0.3241944216877789\n0.5694226438087798\n-1.7658129788900407\n0.4088846416610295\n-0.7532915279942927\n-0.8825700555545382\n-1.0007464896487193\n-1.106313405003533\n-2.239277812062396\n-2.4434284988734087\n-1.4112491981835944\n0.04206086618061139\n-1.5544146764234767\n-0.8711998856126627\n-2.344415408280521\n-0.35727654283718946\n-1.1301366700655626\n-0.07090491219178147\n1.0093781399770716\n-0.07639853682017017\n2.438310059337199\n0.9951493256719846\n-0.041397411036625725\n-0.5273101252325716\n0.6665978941951438\n-0.6781364359039799\n0.4515991708125011\n-0.5383824804275594\n-0.632178255467096\n-0.03058039956788207\n1.1615511337852922\n1.7225498196233717\n-0.40038683425621\n1.970415019013427\n2.3974448690995245\n-0.3534415085206888\n1.682485269708036\n0.2169513963774648\n-1.1097126753434146\n2.55984162737023\n-0.6359720243649178\n-0.6366811726839785\n-1.2683891892677082\n-0.19356105787820752\n-1.1140070341549506\n0.9196112235539385\n0.18257134522741922\n-1.0793741764090032\n-1.4603282023085444\n1.2246075574842963\n-2.1419979302551995\n-1.3697915735778554\n-2.2054878810907312\n-0.06604420724229385\n-1.4403341597737245\n-1.7691257680901344\n1.3394803974537581\n-1.901211254187432\n0.35044457054588635\n0.8817304556825627\n-1.7151061199407434\n-1.8218532743210902\n-2.159646464566434\n-0.063501151845378\n0.10905410186799261\n-1.566137283707012\n2.0205091443470224\n-1.7316321192012083\n-1.6868327099327007\n-0.9241342379028765\n3.444401413246055\n1.3027281272858318\n1.0161681757940755\n3.276623046959969\n-1.8262141570979213\n0.36972235846876744\n0.9729811294376406\n-2.185912099539645\n-2.1315480019962854\n0.9961598276331471\n0.7303432946196609\n-1.9907646881421193\n0.6420919011611613\n0.127186019600731\n1.2351746375594133\n-0.8893076557157883\n-0.31626925561401886\n-1.9035000645808395\n1.2683287729660264\n-1.9056858100531144\n-1.898505446305819\n-1.8980653956215008\n-1.5338098185797833\n1.9288607508331619\n2.0688344241695362\n4.115877622508675\n-1.7610052305816168\n-0.18990399140406905\n0.9993573247052314\n-2.215156973520095\n-0.20689653897688115\n2.1304910122848675\n-2.155841289920801\n-1.748284700082569\n10.700921844730425\n6.157361305113214\n11.502300379691562\n-100\ndone ::\n-1.276899923929392\n-1.3985203739174494\n-1.401290511985593\n-0.897360958589104\n-0.8432561481858261\n-0.14099004145063418\n-0.794147312611475\n0.17795676327369278\n-1.8120690575229343\n0.5412922249175438\n0.6073752745906722\n-1.220049972640993\n-1.2023747269730904\n-0.8700705282976106\n-0.977352193309872\n0.43397601473027747\n-0.8921247573958067\n2.1331116324029167\n2.151867427240552\n1.9222862515730434\n-0.9192053380776883\n-1.5519908742171789\n-1.0140501009430807\n-0.21723570607524267\n2.9922763731609168\n-0.4532429149014001\n-0.7229463790853288\n0.16738191766487034\n-0.43283611075867157\n0.4790751546152591\n1.7805012447069544\n1.741150424194052\n3.5368652717965356\n0.6616123896919259\n5.007904732236759\n3.919558137747026\n-0.4889784145862484\n-0.5062558861383729\n1.3759412158298006\n-0.04270958164909189\n-0.7411318149884483\n4.352360583465688\n-0.5725949905985362\n2.981447305051688\n3.270897107684425\n-0.98250039371149\n1.76683728908518\n0.2596472363172836\n1.407997490854251\n1.9781014768272327\n0.7089850570148201\n0.9498058821926111\n4.00393865579179\n-1.4146447918758724\n-1.6771296023519813\n-1.0379824581515618\n-1.295361668455115\n-1.4085035899740093\n1.9276384363719727\n2.05216579358068\n1.4461526982709016\n-0.9430368856115763\n2.5961153441139344\n-0.8610062402185633\n1.5259061975984367\n-1.2018505003893551\n-1.233726190754993\n3.6357329918473567\n0.8646633051340495\n-1.7109670320550743\n2.1909705048504464\n1.7564191487356084\n0.5185537918552712\n1.6686800577836731\n-1.6923733342391643\n-1.8108584271806478\n-2.0226589224331324\n0.9430813650347261\n-0.39897070468198875\nTerminating Rollout\n"
    }
   ],
   "source": [
    "session.train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([1.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([1.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.]),\n tensor([0.])]"
     },
     "metadata": {},
     "execution_count": 171
    }
   ],
   "source": [
    "session.rollout.dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([1.])"
     },
     "metadata": {},
     "execution_count": 140
    }
   ],
   "source": [
    "torch.Tensor(np.asarray([int(done)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}